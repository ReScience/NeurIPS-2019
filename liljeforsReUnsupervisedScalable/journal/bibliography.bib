@misc{UCRArchive2018,
    title = {The UCR Time Series Classification Archive},
    author = {Dau, Hoang Anh and Keogh, Eamonn and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan 
              and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Yanping and Hu, Bing 
              and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo, and Hexagon-ML},
    year = {2018},
    month = {October},
    note = {\url{https://www.cs.ucr.edu/~eamonn/time_series_data_2018/}}
}

@article{ResNetHe2015,
	author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title = {Deep Residual Learning for Image Recognition},
	journal = {arXiv preprint arXiv:1512.03385},
	year = {2015}
}

@Article{EELines2015,
author="Lines, Jason
and Bagnall, Anthony",
title="Time series classification with ensembles of elastic distance measures",
journal="Data Mining and Knowledge Discovery",
year="2015",
month="May",
day="01",
volume="29",
number="3",
pages="565--592",
abstract="Several alternative distance measures for comparing time series have recently been proposed and evaluated on time series classification (TSC) problems. These include variants of dynamic time warping (DTW), such as weighted and derivative DTW, and edit distance-based measures, including longest common subsequence, edit distance with real penalty, time warp with edit, and move--split--merge. These measures have the common characteristic that they operate in the time domain and compensate for potential localised misalignment through some elastic adjustment. Our aim is to experimentally test two hypotheses related to these distance measures. Firstly, we test whether there is any significant difference in accuracy for TSC problems between nearest neighbour classifiers using these distance measures. Secondly, we test whether combining these elastic distance measures through simple ensemble schemes gives significantly better accuracy. We test these hypotheses by carrying out one of the largest experimental studies ever conducted into time series classification. Our first key finding is that there is no significant difference between the elastic distance measures in terms of classification accuracy on our data sets. Our second finding, and the major contribution of this work, is to define an ensemble classifier that significantly outperforms the individual classifiers. We also demonstrate that the ensemble is more accurate than approaches not based in the time domain. Nearly all TSC papers in the data mining literature cite DTW (with warping window set through cross validation) as the benchmark for comparison. We believe that our ensemble is the first ever classifier to significantly outperform DTW and as such raises the bar for future work in this area.",
issn="1573-756X",
doi="10.1007/s10618-014-0361-2",
url="https://doi.org/10.1007/s10618-014-0361-2"
}


@article{BOSSSchafer:2015:BCT:2833463.2833468,
 author = {Sch\"{a}fer, Patrick},
 title = {The BOSS is Concerned with Time Series Classification in the Presence of Noise},
 journal = {Data Min. Knowl. Discov.},
 issue_date = {November  2015},
 volume = {29},
 number = {6},
 month = nov,
 year = {2015},
 issn = {1384-5810},
 pages = {1505--1530},
 numpages = {26},
 url = {http://dx.doi.org/10.1007/s10618-014-0377-7},
 doi = {10.1007/s10618-014-0377-7},
 acmid = {2833468},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Classification, Fourier transform, Noise, Similarity, Time series},
} 

@InProceedings{STBostrombagnall,
author="Bostrom, Aaron
and Bagnall, Anthony",
editor="Madria, Sanjay
and Hara, Takahiro",
title="Binary Shapelet Transform for Multiclass Time Series Classification",
booktitle="Big Data Analytics and Knowledge Discovery",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="257--269",
abstract="Shapelets have recently been proposed as a new primitive for time series classification. Shapelets are subseries of series that best split the data into its classes. In the original research, shapelets were found recursively within a decision tree through enumeration of the search space. Subsequent research indicated that using shapelets as the basis for transforming datasets leads to more accurate classifiers.",
isbn="978-3-319-22729-0"
}



@INPROCEEDINGS{hivecote,
author={J. {Lines} and S. {Taylor} and A. {Bagnall}},
booktitle={2016 IEEE 16th International Conference on Data Mining (ICDM)},
title={HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based Ensembles for Time Series Classification},
year={2016},
volume={},
number={},
pages={1041-1046},
keywords={neural nets;pattern classification;time series;HIVE-COTE;hierarchical vote collective of transformation-based ensembles;time series classification;TSC algorithms;data representations;CNN structure;modular hierarchical structure;probabilistic voting;interval-based classifier;dictionary classifier;frequency domain classifier;convolutional neural networks;Time series analysis;Machine learning;Machine learning algorithms;Training;Classification algorithms;Prediction algorithms;Dictionaries;time series classification;time series;ensemble classifiers;deep learning},
doi={10.1109/ICDM.2016.0133},
ISSN={},
month={Dec},}

@inproceedings{RWSwu2018random,
title={Random Warping Series: A Random Features Method for Time-Series Embedding},
author={Wu, Lingfei and Yen, Ian En-Hsu and Yi, Jinfeng and Xu, Fangli and Lei, Qi and Witbrock, Michael},
booktitle={International Conference on Artificial Intelligence and Statistics},
pages={793--802},
year={2018}
}

@article{TimenetMalhotraTVAS17,
  author    = {Pankaj Malhotra and
               Vishnu TV and
               Lovekesh Vig and
               Puneet Agarwal and
               Gautam Shroff},
  title     = {TimeNet: Pre-trained deep recurrent neural network for time series
               classification},
  journal   = {CoRR},
  volume    = {abs/1706.08838},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.08838},
  archivePrefix = {arXiv},
  eprint    = {1706.08838},
  timestamp = {Mon, 13 Aug 2018 16:46:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MalhotraTVAS17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{Pytorchpaszke2017automatic,
  title={Automatic Differentiation in {PyTorch}},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS Autodiff Workshop},
  year={2017}
}

@misc{henderson2017reinforcement,
  abstract = {In recent years, significant progress has been made in solving challenging
problems across various domains using deep reinforcement learning (RL).
Reproducing existing work and accurately judging the improvements offered by
novel methods is vital to sustaining this progress. Unfortunately, reproducing
results for state-of-the-art deep RL methods is seldom straightforward. In
particular, non-determinism in standard benchmark environments, combined with
variance intrinsic to the methods, can make reported results tough to
interpret. Without significance metrics and tighter standardization of
experimental reporting, it is difficult to determine whether improvements over
the prior state-of-the-art are meaningful. In this paper, we investigate
challenges posed by reproducibility, proper experimental techniques, and
reporting procedures. We illustrate the variability in reported metrics and
results when comparing against common baselines and suggest guidelines to make
future results in deep RL more reproducible. We aim to spur discussion about
how to ensure continued progress in the field by minimizing wasted effort
stemming from results that are non-reproducible and easily misinterpreted.},
  added-at = {2018-02-07T04:57:21.000+0100},
  author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  biburl = {https://www.bibsonomy.org/bibtex/2b5bd5f75948f959eac4a2bf2fce9ef42/achakraborty},
  description = {[1709.06560] Deep Reinforcement Learning that Matters},
  interhash = {6f4ef32093f8db0b16430338bda8a326},
  intrahash = {b5bd5f75948f959eac4a2bf2fce9ef42},
  keywords = {2017 arxiv deep-learning reinforcement-learning},
  note = {cite arxiv:1709.06560Comment: Accepted to the Thirthy-Second AAAI Conference On Artificial  Intelligence (AAAI), 2018},
  timestamp = {2018-02-07T04:57:21.000+0100},
  title = {Deep Reinforcement Learning that Matters},
  url = {http://arxiv.org/abs/1709.06560},
  year = 2017
}




@article{Hyper1Melis,
  author    = {G{\'{a}}bor Melis and
               Chris Dyer and
               Phil Blunsom},
  title     = {On the State of the Art of Evaluation in Neural Language Models},
  journal   = {CoRR},
  volume    = {abs/1707.05589},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.05589},
  archivePrefix = {arXiv},
  eprint    = {1707.05589},
  timestamp = {Mon, 13 Aug 2018 16:47:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MelisDB17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{LiptonTroubling,
 author = {Lipton, Zachary C. and Steinhardt, Jacob},
 title = {Troubling Trends in Machine Learning Scholarship},
 journal = {Queue},
 issue_date = {January-February 2019},
 volume = {17},
 number = {1},
 month = feb,
 year = {2019},
 issn = {1542-7730},
 pages = {80:45--80:77},
 articleno = {80},
 numpages = {33},
 url = {http://doi.acm.org/10.1145/3317287.3328534},
 doi = {10.1145/3317287.3328534},
 acmid = {3328534},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

    
@article{bagnall2018uea,
  title={The UEA multivariate time series classification archive, 2018},
  author={Bagnall, Anthony and Dau, Hoang Anh and Lines, Jason and Flynn, Michael and Large, James and Bostrom, Aaron and Southam, Paul and Keogh, Eamonn},
  journal={arXiv preprint arXiv:1811.00075},
  year={2018}
}

@misc{Dua:2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{FranceschiUnsupervised2019,
  author    = {Jean{-}Yves Franceschi and
               Aymeric Dieuleveut and
               Martin Jaggi},
  title     = {Unsupervised Scalable Representation Learning for Multivariate Time
               Series},
  journal   = {CoRR},
  volume    = {abs/1901.10738},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.10738},
  archivePrefix = {arXiv},
  eprint    = {1901.10738},
  timestamp = {Sun, 03 Feb 2019 14:23:05 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1901-10738},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ogtriplet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{fawaz2019deep,
  title={Deep learning for time series classification: a review},
  author={Fawaz, Hassan Ismail and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
  journal={Data Mining and Knowledge Discovery},
  volume={33},
  number={4},
  pages={917--963},
  year={2019},
  publisher={Springer}
}