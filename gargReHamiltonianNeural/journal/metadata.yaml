# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it shoudl be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[Â¬Re]"
#  - For other article types, no instruction (but please, not too long)
title: "[Re] Hamiltonian Neural Networks"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author
authors:
  - name: Ayush Garg
    orcid: 
    email: ayush.g@iitgn.ac.in
    affiliations: 1,*
    
  - name: Sammed Shantinath Kagi
    orcid: 
    email: sammed.shantinath@iitgn.ac.in
    affiliations: 1      # * is for contact author

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    Computer Science and Engineering, Indian Institute of Technology, Gandhinagar
    address: Gandhinagar, India


# List of keywords (adding the programming language might be a good idea)
keywords: hamiltonian neural networks, pytorch

# Code URL and DOI (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo,
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/ayushgarg31/HNN-Neurips2019
  - doi: 
  - swh: swh:1:dir:c5f6842bd19932d0f3db7bf09b5174e4d5240ad9

# Date URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "Greydanus, Samuel, Misko Dzamba, and Jason Yosinski. \"Hamiltonian neural networks.\" Advances in Neural Information Processing Systems. 2019." # Full textual citation
 - bib:  \fullcite{greydanus}
 # Bibtex key (if any) in your bibliography file
 - url:  https://papers.nips.cc/paper/9672-hamiltonian-neural-networks.pdf
 # URL to the PDF, try to link to a non-paywall version
 - doi:  # Regular digital object identifier

# Don't forget to surround abstract with double quotes
abstract: "Even though neural networks enjoy widespread use, they still struggle to learn the basic laws of physics. How might we endow them with better inductive biases? In this paper, we draw inspiration from Hamiltonian mechanics to train models that learn and respect exact conservation laws in an unsupervised manner. We evaluate our models on problems where conservation of energy is important, including the two-body problem and pixel observations of a pendulum. Our model trains faster and generalizes better than a regular neural network. An interesting side effect is that our model is perfectly reversible in time."

# Bibliography file (yours)
bibliography: bibliography.bib
  
# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: NeurIPS 2019 Reproducibility Challenge

# Coding language (main one only if several)
language: Python

  
# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review: 
  - url: https://openreview.net/forum?id=HJxNSp9MTr

contributors:
  - name: Koustuv Sinha
    orcid: 0000-0002-2803-9236
    role: editor
  - name: Anonymous Reviewers
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer

# This information will be provided by the editor
dates:
  - received:  February 15, 2020
  - accepted:
  - published: 

# This information will be provided by the editor
article:
  - number: # Article number will be automatically assigned during publication
  - doi:    # DOI from Zenodo
  - url:    # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name:   "ReScience C"
  - issn:   2430-3658
  - volume: 6
  - issue:  1
